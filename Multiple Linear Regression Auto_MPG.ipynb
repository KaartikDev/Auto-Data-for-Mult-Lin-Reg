{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd27fb4-342b-4073-ba4d-f482b520e195",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression Model Analyzing the MPG of Autos in 1970-80\n",
    "### Intro:\n",
    "\n",
    "This project was created as an in-depth exploration into linear regression models taking multiple inputs and provindg a single output \"guess.\" This program takes in the amount of cylinders, engine displacment, horespower, weight, acceleration, and year of maunfcature to predict mpg of a car. Note: Not allowed to use scikit or similar library\n",
    "\n",
    "Exploration includes extracting data from a spreadsheet, feature normalization,  gradient descent, graphing cost v iteration, and calculating % error of model.\n",
    "\n",
    "The Training data set can be found on https://archive-beta.ics.uci.edu/dataset/9/auto+mpg \n",
    "\n",
    "Author: Kaartik Tejwani  \n",
    "Version: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41fcfb15-b9a8-401d-9863-c501d0922c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# data tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization for models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# data analysis tools\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "%load_ext watermark\n",
    "\n",
    "import time\n",
    "#prevent changing global vars\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "497aff68-7ea7-4ec5-91f8-d0737f97b6f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.3\n",
      "IPython version      : 8.13.2\n",
      "\n",
      "pandas    : 2.0.1\n",
      "numpy     : 1.24.3\n",
      "matplotlib: 3.7.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -p pandas,numpy,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d163a58-6ab8-4955-b49e-6f7a57c7647d",
   "metadata": {},
   "source": [
    "### Extracting Data\n",
    "\n",
    "Using pandas to extract data from excel workbook containg data. Then storing data in numpy arrays.\n",
    "\n",
    "Also, creating weights array and initial constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44808579-1011-4e7d-a1bc-675dc82b809f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_excel('C:/Users/Public/Documents/Auto Data.xlsx', engine=\"openpyxl\", sheet_name='auto-mpg')\n",
    "\n",
    "#target values\n",
    "MPG_data = df['MPG']  # Replace 'column_name' with the actual name of the column\n",
    "MPG_array = np.array(MPG_data)\n",
    "\n",
    "#create an empty list to append DataFrame rows\n",
    "data_rows = []\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    temp = np.array(row)\n",
    "    #eliminate first and last two elements; they are not in model\n",
    "    temp = temp[1:len(temp)-2] \n",
    "    data_rows.append(temp)\n",
    "\n",
    "#stack the data rows to create a numpy array\n",
    "trainData = np.vstack(data_rows)\n",
    "trainDataShape = trainData.shape\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e9edb-a17f-4f56-be85-b4370aa57eca",
   "metadata": {},
   "source": [
    "### Normalizing data using mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12b8977-885e-40c0-97b2-dd8a75e33e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_normalize(data):\n",
    "    \"\"\"\n",
    "    A scalar output using the model\n",
    "    Args:\n",
    "      data (ndarray): Shape (m,n) array with m data points and n features\n",
    "      \n",
    "    Returns:\n",
    "      dataCopy (ndarray):  mean normalized data\n",
    "    \"\"\"\n",
    "    dataCopy = copy.deepcopy(data)\n",
    "    dataShape = dataCopy.shape\n",
    "    \n",
    "    # empty list to store each features unique mean\n",
    "    means = []\n",
    "    #empty list to store each features unqiue range\n",
    "    rangeOfData = []\n",
    "    \n",
    "    # Use nested for loop to get calculate mean and range for datset\n",
    "    for col in range(dataShape[1]):\n",
    "        nums = []\n",
    "        for row in range(dataShape[0]):\n",
    "            nums.append(data[row][col])\n",
    "        avg = np.mean(np.array(nums))\n",
    "        rangeOfCol = np.ptp(np.array(nums))\n",
    "        means.append(avg)\n",
    "        rangeOfData.append(rangeOfCol)\n",
    "    \n",
    "    # Use second nested for loop to get normalize datset\n",
    "    for col in range(dataShape[1]):\n",
    "        for row in range(dataShape[0]):\n",
    "            dataCopy[row][col] = (dataCopy[row][col] - means[col])/ rangeOfData[col]\n",
    "    \n",
    "    \n",
    "    return dataCopy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc76f72-ec05-4fed-a685-804336eba562",
   "metadata": {},
   "source": [
    "### Defining Model and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ff661f7-9b57-430e-8bfa-8a9582f60d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predictMPG(datapoint, weights, b): \n",
    "    \"\"\"\n",
    "    A scalar output using the model\n",
    "    Args:\n",
    "      datapoint (ndarray): Shape (n,1) array with multiple features\n",
    "      weights (ndarray): Shape (n, 1) model parameters   \n",
    "      b (scalar):             model parameter \n",
    "      \n",
    "    Returns:\n",
    "      guess (scalar):  prediction/guess\n",
    "    \"\"\"\n",
    "    guess = np.dot(datapoint, weights) + b     \n",
    "    return guess\n",
    "\n",
    "def cost_function(data, targets, weights, b):\n",
    "    \"\"\"\n",
    "    Sqared cost of current parameters\n",
    "    Args:\n",
    "      data (ndarray (m,n)): Full data, m number of datapoints and n different featres\n",
    "      targets (ndarray): Shape (n,1) actual model\n",
    "      weights (ndarray): Shape (n, 1) model parameters   \n",
    "      b (scalar):             model parameter \n",
    "    Returns:\n",
    "      cost (scalar):  sqared cost\n",
    "    \"\"\"\n",
    "    NumPoints = data.shape[0]\n",
    "    cost = 0.0\n",
    "    \n",
    "    for i in range(NumPoints):\n",
    "        #perdicts MPG and compres to actual (given) MPG\n",
    "        cost += (predictMPG(data[i], weights, b) - targets[i])**2\n",
    "    cost = cost / (2*NumPoints)\n",
    "    return cost\n",
    "\n",
    "def calc_gradient(data, targets, weights, b):\n",
    "    \"\"\"\n",
    "    Calculates the gradient for the cost function using partial deritaves of weights,b\n",
    "    Args:\n",
    "      data (ndarray (m,n)): Full data, m number of datapoints and n different featres\n",
    "      targets (ndarray): Shape (n,1) actual model\n",
    "      weights (ndarray): Shape (n, 1) model parameters   \n",
    "      b (scalar):             model parameter \n",
    "    Returns:\n",
    "      deriv_dw (ndarrary (n,1)): Gradient of cost function with respect to weights\n",
    "      deriv_db (scalar): Gradeint of cost function with respect to b\n",
    "      \n",
    "    \"\"\"\n",
    "    dataShape = data.shape\n",
    "    deriv_dw = np.zeros(weights.shape)\n",
    "    deriv_db = 0\n",
    "\n",
    "    for i in range(dataShape[0]): #392 data points\n",
    "        error = predictMPG(data[i], weights, b) - targets[i]\n",
    "        for w in range(dataShape[1]): #6 for 6 different features\n",
    "            deriv_dw[w] += (error * data[i,w])\n",
    "        deriv_db += error\n",
    "\n",
    "    return (deriv_dw / dataShape[0]), (deriv_db / dataShape[0])\n",
    "\n",
    "def perform_grad(data, targets, weightsIn, bIn, alpha, iters):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to update/learn weights and b. Updates weights and b by taking \n",
    "    iters gradient steps with rate alpha\n",
    "    \n",
    "    Args:\n",
    "      data (ndarray (m,n)): Full data, m number of datapoints and n different featres\n",
    "      targets (ndarray): Shape (n,1) actual model\n",
    "      weightsIN (ndarray): Shape (n, 1) initial model parameters   \n",
    "      bIn (scalar):             initoal model parameter \n",
    "      alpha (float): Learning rate\n",
    "      iters (int): number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,1)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      costHist (ndarray (n,1)): Hisotry of cost function\n",
    "      iterations (ndarray (n,1)): Iteration when cost was recorded\n",
    "    \"\"\"\n",
    "    w = copy.deepcopy(weightsIn)\n",
    "    b = bIn\n",
    "    costHist = []\n",
    "    iterations = []\n",
    "    for i in range(iters):\n",
    "        derivW, derivB = calc_gradient(data, targets, w, b)\n",
    "        w = w - alpha * derivW\n",
    "        b = b - alpha * derivB\n",
    "        if i % 5 == 0:\n",
    "            costHist.append(cost_function(data, targets, w, b))\n",
    "            iterations.append(i)\n",
    "    return w, b, costHist, iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1491c43e-5fdd-45a2-91b9-e31e8874e28f",
   "metadata": {},
   "source": [
    "### Main Program and Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29324f7d-4652-4a62-8e3b-917644381fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of datapoints is 392 and the number of features is 6\n",
      "\n",
      "the training data is formatted as: \n",
      "[pistons displacement horsepower weight acceleration year]\n",
      "[[8 307.0 130 3504 12.0 70]\n",
      " [8 350.0 165 3693 11.5 70]\n",
      " [8 318.0 150 3436 11.0 70]\n",
      " ...\n",
      " [4 135.0 84 2295 11.6 82]\n",
      " [4 120.0 79 2625 18.6 82]\n",
      " [4 119.0 82 2720 19.4 82]]\n",
      "\n",
      "performing mean normalization\n",
      "the normalized training data is:\n",
      "[[0.5056122448979592 0.29092509096661917 0.13875332741792365\n",
      "  0.14925313760321254 -0.2107932458697764 -0.49829931972789154]\n",
      " [0.5056122448979592 0.4020362020777303 0.32897071872227146\n",
      "  0.20283975512518587 -0.24055515063168115 -0.49829931972789154]\n",
      " [0.5056122448979592 0.3193488635764383 0.2474489795918367\n",
      "  0.12997329637837557 -0.2703170553935859 -0.49829931972789154]\n",
      " ...\n",
      " [-0.29438775510204085 -0.15351935347782525 -0.11124667258207635\n",
      "  -0.1935310982913154 -0.23460276967930022 0.5017006802721085]\n",
      " [-0.29438775510204085 -0.19227904340030588 -0.13842058562555462\n",
      "  -0.0999671629354889 0.18206389698736652 0.5017006802721085]\n",
      " [-0.29438775510204085 -0.19486302272847125 -0.12211623779946765\n",
      "  -0.07303209063608432 0.22968294460641397 0.5017006802721085]]\n",
      "\n",
      "performing gradient descent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initial parameter (weights)\n",
    "weights = np.array([-5.1871476,  -4.29174755, -3.3185558,  -3.29637758,  0.9904946,   3.81195076])\n",
    "# initial parameter (y intercept)\n",
    "b = 23.44416896380101\n",
    "# Speed of Linear Regression (scales change in parameters per iteration)\n",
    "alpha = 0.0001\n",
    "#number of steps in grad desc\n",
    "iters = 5000\n",
    "\n",
    "print(f\"The number of datapoints is {trainDataShape[0]} and the number of features is {trainDataShape[1]}\")\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"the training data is formatted as: \")\n",
    "print(\"[pistons displacement horsepower weight acceleration year]\")\n",
    "print(trainData)\n",
    "\n",
    "print()\n",
    "print(\"performing mean normalization\")\n",
    "print(\"the normalized training data is:\")\n",
    "NormData = mean_normalize(trainData)\n",
    "print(NormData)\n",
    "\n",
    "print()\n",
    "print(\"performing gradient descent\")\n",
    "finW, finB, costs, reps = perform_grad(NormData, MPG_array, weights, b, alpha, iters)\n",
    "\n",
    "#Graphing cost v iteration\n",
    "x = reps\n",
    "y1 = costs\n",
    "\n",
    "plt.plot(x, y1, label='Cost')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Sqared error')\n",
    "plt.title('Sqared Error vs Number of Iterations')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"The final weights were {finW} and b was {finB}\")\n",
    "print(f\"The final cost is {cost_function(NormData, MPG_array, finW, finB)}\")\n",
    "\n",
    "testArr = np.array([6, 250, 105, 3353, 14.5, 76])\n",
    "testMean = np.mean(testArr)\n",
    "testRange = np.ptp(testArr)\n",
    "for i in range(testArr.shape[0]):\n",
    "    testArr[i]  = (testArr[i] - testMean) / testRange\n",
    "print(testArr)\n",
    "print(\"test case: [6\t250\t105\t3353\t14.5\t76]\")\n",
    "print(\"correct answer: 22 MPG\")\n",
    "print(f\"model predicts {predictMPG(testArr, finW, finB)}\")\n",
    "print(f\"percent error is {(predictMPG(testArr, finW, finB) - 22)*100/22}\")\n",
    "print(\"5% NOT BAD :D\")\n",
    "#Other tests showed similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a0f6d-48fb-4365-b2e4-cd945f109b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
